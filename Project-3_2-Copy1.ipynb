{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas_profiling\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, roc_auc_score\n",
    "\n",
    "import statsmodels\n",
    "\n",
    "from yellowbrick.classifier import ClassificationReport, ROCAUC\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('parkinsons.data', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.profile_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,20))\n",
    "\n",
    "sns.heatmap(df.corr(),\n",
    "            annot=True,\n",
    "            linewidths=.5,\n",
    "            center=0,\n",
    "            cbar=True,\n",
    "            cmap=\"YlGnBu\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform basic data pre-processing (if needed), univariate and bivariate analysis. Use relevant visualizations to understand the features at hand. Which features are strongly correlated to the target variable? - 15\n",
    "\n",
    "# - Spread1, Spread2 and PPE are strongly co-related with the target variable status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#levels of Y variable\n",
    "df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('parkinsons.data')\n",
    "df = df.drop('name',axis=1)\n",
    "sns.pairplot(df,hue='status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revised = df.drop(columns = ['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revised.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revised.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Pairplot below clearly shows the high co-relation between different parameters and status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_revised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The joint plots below cleary shows how the Patients with Parkinsons (status = 1) and without Parkinsons (status = 0) are divided across different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"MDVP:Fo(Hz)\", y=\"status\", data=df_revised);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"HNR\", y=\"status\", data=df_revised);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"spread1\", y=\"status\", data=df_revised);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"spread2\", y=\"status\", data=df_revised);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"PPE\", y=\"status\", data=df_revised);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"MDVP:Jitter(%)\", y=\"status\", data=df_revised);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"MDVP:PPQ\", y=\"status\", data=df_revised);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"MDVP:Shimmer\", y=\"status\", data=df_revised);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"MDVP:Shimmer\", y=\"status\", data=df_revised);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"MDVP:Shimmer(dB)\", y=\"status\", data=df_revised);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"Shimmer:APQ3\", y=\"status\", data=df_revised);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"Shimmer:APQ5\", y=\"status\", data=df_revised);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"MDVP:APQ\", y=\"status\", data=df_revised);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"Shimmer:DDA\", y=\"status\", data=df_revised);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into training and test set for independent attributes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = [col for col in df_revised.columns if col != 'status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_revised[features], df_revised['status'], test_size=.3, random_state=22)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoking the decision tree classifier function. Using 'entropy' method of finding the split columns. Other option \n",
    "# could be gini index.  \n",
    "\n",
    "model_entropy = DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_entropy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train AUC: %.2f\" % roc_auc_score(y_train, model_entropy.predict(X_train), multi_class = 'ovo', average = 'weighted'))  # performance on train data\n",
    "print(\"Test AUC: %.2f\" % roc_auc_score(y_test, model_entropy.predict(X_test), multi_class = 'ovo', average = 'weighted'))  # performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The decision tree is overfitting, in order to resole this issue pruning the tree to max depth of 3\n",
    "clf_pruned = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 3)\n",
    "clf_pruned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train AUC: %.2f\" % roc_auc_score(y_train, clf_pruned.predict(X_train), multi_class = 'ovo', average = 'weighted'))  # performance on train data\n",
    "print(\"Test AUC: %.2f\" % roc_auc_score(y_test, clf_pruned.predict(X_test), multi_class = 'ovo', average = 'weighted'))  # performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(clf_pruned, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True,feature_names = features,class_names=['0','1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('wines_pruned.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = clf_pruned.predict(X_train)\n",
    "preds_test = clf_pruned.predict(X_test)\n",
    "\n",
    "AUC_DT_train = roc_auc_score(y_train, clf_pruned.predict(X_train), multi_class = 'ovo', average = 'weighted')\n",
    "AUC_DT_test = roc_auc_score(y_test, clf_pruned.predict(X_test), multi_class = 'ovo', average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "pd.crosstab(y_test, preds_test, rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance with yellowbrick library\n",
    "viz = ClassificationReport(DecisionTreeClassifier(criterion = \"entropy\", max_depth=3))\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.show()\n",
    "\n",
    "roc = ROCAUC(DecisionTreeClassifier(criterion = \"entropy\", max_depth=3))\n",
    "roc.fit(X_train, y_train)\n",
    "roc.score(X_test, y_test)\n",
    "roc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating feature importance\n",
    "\n",
    "feat_importance = clf_pruned.tree_.compute_feature_importances(normalize=False)\n",
    "\n",
    "feat_imp_dict = dict(zip(features, clf_pruned.feature_importances_))\n",
    "feat_imp = pd.DataFrame.from_dict(feat_imp_dict, orient='index', columns = ['importance'])\n",
    "feat_imp.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the accuracy results for each model in a dataframe for final comparison\n",
    "resultsDf = pd.DataFrame({'Method':['Decision Tree'], \n",
    "                          'AUC Train': AUC_DT_train,\n",
    "                          'AUC Test': AUC_DT_test})\n",
    "resultsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evalaue the performance of the model\n",
    "def evaluate_model(model):\n",
    "    auc_train = roc_auc_score(y_train, model.predict(X_train), multi_class = 'ovo', average = 'weighted')\n",
    "    auc_test = roc_auc_score(y_test, model.predict(X_test), multi_class = 'ovo', average = 'weighted')\n",
    "    \n",
    "    return auc_train, auc_test\n",
    "\n",
    "\n",
    "# Function to Visualize the models\n",
    "def visClassifierResults(model_w_parameters):\n",
    "    viz = ClassificationReport(model_w_parameters)\n",
    "    viz.fit(X_train, y_train)\n",
    "    viz.score(X_test, y_test)\n",
    "    viz.show()\n",
    "    \n",
    "    roc = ROCAUC(model_w_parameters)\n",
    "    roc.fit(X_train, y_train)\n",
    "    roc.score(X_test, y_test)\n",
    "    roc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revised.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=50, random_state=1).fit(X_train, y_train)\n",
    "\n",
    "scores = evaluate_model(rf)\n",
    "\n",
    "resultsDf.loc[1] = ['Random Forest', scores[0], scores[1]]\n",
    "resultsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visClassifierResults(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Adaptive Boosting\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abcl = AdaBoostClassifier(n_estimators=50, learning_rate=0.1, random_state=1).fit(X_train, y_train)\n",
    "\n",
    "scores = evaluate_model(abcl)\n",
    "\n",
    "resultsDf.loc[2] = ['AdaBoost', scores[0], scores[1]]\n",
    "resultsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visClassifierResults(abcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Bagging Classifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bgcl = BaggingClassifier(n_estimators=50, max_samples=0.7, random_state=1).fit(X_train, y_train)\n",
    "\n",
    "scores = evaluate_model(bgcl)\n",
    "\n",
    "resultsDf.loc[3] = ['Bagging', scores[0], scores[1]]\n",
    "resultsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visClassifierResults(bgcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implmenting Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbcl = GradientBoostingClassifier(n_estimators=50, learning_rate=0.1, random_state=1).fit(X_train, y_train)\n",
    "\n",
    "scores = evaluate_model(gbcl)\n",
    "\n",
    "resultsDf.loc[4] = ['Gradient Boosting', scores[0], scores[1]]\n",
    "resultsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visClassifierResults(gbcl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
